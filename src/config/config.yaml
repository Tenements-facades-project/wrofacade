device: 'cpu' # [cpu | cuda | mps]
label2clr_path: "label2clr.json"

---
label2clr: 
  noise: [  0]
  door: [  110]
  window: [  240]
  portal: [  200]
  window_casing: [  250]
  pediment: [  230]
  cornice/horizontal_element: [  80]
  pilaster/vertical_element: [  60]
  balcony: [  140]
  roof: [  160]
  detail: [  180]
  wall: [  30]
--- 
translator:
  checkpoints_dir: 'checkpoints/pix2pix/' # models are stored here
  isTrain: False # set training mode
  gan_mode: 'vanilla' # the type of GAN objective, supports vanilla, lsgan, and wgangp
  input_nc: 1 # no. of input image channels: 3 for RGB and 1 for grayscale
  output_nc: 3 # no. of output image channels: 3 for RGB and 1 for grayscale
  ngf: 64 # no. of gen filters in the last conv layer
  ndf: 64 # no. of discrim filters in the first conv layer
  netD: 'basic' # specify discriminator architecture [basic | n_layers | pixel]. The basic model is a 70x70 PatchGAN. n_layers allows you to specify the layers in the discriminator
  netG: 'unet_256' # specify generator architecture [resnet_9blocks | resnet_6blocks | unet_256 | unet_128]
  n_layers_D: 3 # only used if netD==n_layers
  norm: 'batch' # instance normalization or batch normalization [instance | batch | none]
  init_type: 'normal' # network initialization [normal | xavier | kaiming | orthogonal]
  init_gain: 0.02 # scaling factor for normal, xavier and orthogonal.
  no_dropout: True # no dropout for the generator
  save_by_iter: True # whether saves model by iteration
  load_epoch: 250 # which epoch to load model from when generating images
  load_iter: 0
  verbose: False 
  # dataset parameters
  dataset: 'wro' # chooses dataset to load [cmp | wro]
  load_size: 286 # scale images to this size
  crop_size: 256 # then crop to this size
  preprocess: 'scale_width_and_crop' # scaling and cropping of images at load time [resize_and_crop | crop | scale_width | scale_width_and_crop | none]
  no_flip: True # if specified, do not flip the images for data augmentation
  root_path: '/data/' # path to images (should have subfolders trainA, trainB, valA, valB, etc)

---
segmentator:
  model_name_or_path: 'Tenements-facades-project/segfacade_model'
  local_files_only: False

---
torchGAN:
  checkpoint_path: 'checkpoints/stackGan/netG_56500.pth'
  input_dim: 100
  distribution: "normal"
  device: 'cuda'

---
grammars_masks:
  grammar_pickle_path: "checkpoints_final/checkpoint_10.pickle"
  n_attempts: 20

---
grammars_pure:
  grammar_pickle_path: "checkpoints_final/checkpoint_10.pickle"
